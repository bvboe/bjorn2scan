import threading
import json
import os
import logging
logger = logging.getLogger(__name__)

IMAGE_CACHE_TYPE = "image"
NODE_CACHE_TYPE = "node"

class CacheMetadata:
    def __init__(self, cache_type, data_on_disk = False):
        if not (cache_type == IMAGE_CACHE_TYPE or cache_type == NODE_CACHE_TYPE):
            raise TypeError("cache_type must either be IMAGE_CACHE_TYPE or NODE_CACHE_TYPE")

        self.cache_type = cache_type
        self.data_on_disk = data_on_disk

class ApiCache:
    _instance = None
    cache = {}
    change_metadata = {}
    lock = threading.Lock()
    CACHE_DIRECTORY = os.getenv("CACHE_DIRECTORY")

    def __new__(cls):
        logger.info("ApiCache.__new__")
        if cls._instance is None:
            cls._instance = super(ApiCache, cls).__new__(cls)
            os.makedirs(cls._instance.CACHE_DIRECTORY, exist_ok=True)
            cls._instance.change_metadata[IMAGE_CACHE_TYPE] = cls._instance.increment_change_metadata(None)
            cls._instance.change_metadata[NODE_CACHE_TYPE] = cls._instance.increment_change_metadata(None)

        return cls._instance

    @staticmethod
    def increment_change_metadata(current_metadata):
        from datetime import datetime, timezone
        """Increment revision_number and set last_update to the current UTC time."""
        revision = (current_metadata or {}).get('revision_number', -1) + 1
        return {
            "last_updated": datetime.now(timezone.utc).isoformat(),
            "revision_number": revision
        }
    
    def init_cache(self, key, cache_type):
        logger.debug(f"ApiCache.init_cache({key}, {cache_type})")
        with self.lock:
            if key not in self.cache:
                self.cache[key] = CacheMetadata(cache_type)

    def get_json(self, key):
        logger.debug(f"ApiCache.get_json({key})")
        string_result = self.get_string(key)
        if string_result is None:
            return None
        else:
            return json.loads(string_result)

    def get_string(self, key):
        logger.debug(f"ApiCache.get_string({key})")
        with self.lock:
            if self.cache[key].data_on_disk == False:
                return None
            else:
                with open(self.CACHE_DIRECTORY + "/" + key, 'r') as file:
                    return file.read()

    def get_strings(self, key):
        logger.debug(f"ApiCache.get_strings({key})")
        with self.lock:
            if self.cache[key].data_on_disk == False:
                return None
            else:
                with open(self.CACHE_DIRECTORY + "/" + key, 'r') as file:
                    result = []
                    for line in file:
                        result.append(line.rstrip('\n'))

                    return result
    
    def set_json(self, key, json_value):
        logger.debug(f"ApiCache.set_json({key}, ...)")
        self.set_string(key, json.dumps(json_value))

    def set_string(self, key, string):
        logger.debug(f"ApiCache.set_string({key}, ...)")
        with self.lock:
            with open(self.CACHE_DIRECTORY + "/" + key, 'w') as file:
                # Write status
                file.write(string)

            self.cache[key].data_on_disk = True

    def set_strings(self, key, strings_value):
        logger.debug(f"ApiCache.set_strings({key}, ...)")
        with self.lock:
            with open(self.CACHE_DIRECTORY + "/" + key, 'w') as file:
                # Write status
                file.writelines(f"{line}\n" for line in strings_value)

            self.cache[key].data_on_disk = True

    def get_or_set_strings(self, key, cache_type, function_ref):
        logger.debug(f"ApiCache.get_or_set_strings({key}, {cache_type}, ...)")
        self.init_cache(key, cache_type)
        value = self.get_strings(key)
        if value is None:
            value = function_ref()
            self.set_strings(key, value)
        return value

    def get_or_set_string(self, key, cache_type, function_ref):
        logger.debug(f"ApiCache.get_or_set_string({key}, {cache_type}, ...)")
        self.init_cache(key, cache_type)
        value = self.get_string(key)
        if value is None:
            value = function_ref()
            self.set_string(key, value)
        return value

    def get_or_set_json(self, key, cache_type, function_ref):
        logger.debug(f"ApiCache.get_or_set_json({key}, {cache_type}, ...)")
        self.init_cache(key, cache_type)
        value = self.get_json(key)
        if value is None:
            value = function_ref()
            self.set_json(key, value)
        return value

    def clear_caches(self, cache_type = None):
        logger.debug(f"ApiCache.clear_caches({cache_type})")
        with self.lock:
            if cache_type is None:
                self.change_metadata[IMAGE_CACHE_TYPE] = self.increment_change_metadata(self.change_metadata[IMAGE_CACHE_TYPE])
                self.change_metadata[NODE_CACHE_TYPE] = self.increment_change_metadata(self.change_metadata[NODE_CACHE_TYPE])
            else:
                self.change_metadata[cache_type] = self.increment_change_metadata(self.change_metadata[cache_type])

            for metadata in self.cache.values():
                if cache_type is None or metadata.cache_type == cache_type:
                    metadata.data_on_disk = False

    def get_status(self):
        logger.debug(f"ApiCache.get_status()")
        result = []
        with self.lock:
            for cache, metadata in self.cache.items():
                data = {
                    "cache_name": cache,
                    "cache_type": metadata.cache_type,
                    "data_on_disk": metadata.data_on_disk
                }
                result.append(data)

        return result
    
    def get_change_metadata(self, cache_type):
        logger.debug(f"ApiCache.get_change_metadata({cache_type})")
        with self.lock:
            if cache_type is not None:
                return self.change_metadata[cache_type]
            else:
                # Go through all metadata, add up the revision numbers and return the latest timestamp
                from datetime import datetime

                total_revision = 0
                latest_timestamp = None

                for metadata in self.change_metadata.values():
                    total_revision += metadata['revision_number']
                    timestamp = datetime.fromisoformat(metadata['last_updated'])
                    if latest_timestamp is None or timestamp > latest_timestamp:
                        latest_timestamp = timestamp

                return {
                    "last_updated": latest_timestamp.isoformat() if latest_timestamp else None,
                    "revision_number": total_revision
                }